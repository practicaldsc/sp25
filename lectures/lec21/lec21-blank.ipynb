{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a1bb31",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from lec_utils import *\n",
    "import lec21_util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b5a42",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\" markdown=\"1\">\n",
    "\n",
    "#### Lecture 21\n",
    "\n",
    "# Introduction to Classification\n",
    "\n",
    "### EECS 398: Practical Data Science, Spring 2025\n",
    "\n",
    "<small><a style=\"text-decoration: none\" href=\"https://practicaldsc.org\">practicaldsc.org</a> ‚Ä¢ <a style=\"text-decoration: none\" href=\"https://github.com/practicaldsc/sp25\">github.com/practicaldsc/sp25</a> ‚Ä¢ üì£ See latest announcements [**here on Ed**](https://edstem.org/us/courses/78535/discussion/6647877) </small>\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2576fc44",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda üìÜ\n",
    "\n",
    "- Classification overview.\n",
    "- Survey of classification methods.\n",
    "    - $k$-nearest neighbors üè°üè†.\n",
    "    - Decision trees üéÑ.\n",
    "- Evaluating classifiers.\n",
    "- Multiclass classification üêß."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84abdd4f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e50f0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification overview\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff09468",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The taxonomy of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1668c2db",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So far, we've focused on building **regression** models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a5f4e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Regression is a form of **supervised learning**, in which the target variable (i.e., the $y$-values we're trying to predict) is **numerical**.<br><small>For example, a predicted commute time could technically be any real number.</small>\n",
    "\n",
    "<center><img src=\"imgs/taxonomy.svg\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b669f4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Next, we'll focus on **classification**, a form of supervised learning in which the target variable is **categorical**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b33f0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fef41d9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Does this person have diabetes?<br><small>This is an example of **binary classification** ‚Äì there are only two possible classes, or categories. In binary classification, the two classes are typically **1** (yes) and **0** (no).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7672d2ab",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Is this digit a 0, 1, 2, 3, 4, 5, 6, 7, 8, or 9?<br><small>This is an example of multi-class classification, where there are multiple possible classes.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302615cd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Is this picture of a dog, cat, zebra, or hamster?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be64b2d6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a86388",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When we introduced regression, we **started** by understanding the theoretical foundations on paper, and then learned how to build models in `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98146e8f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This time, we'll do the reverse: we'll start by learning how to use classifiers in `sklearn`, and then over the next few lectures, we'll dive deeper into the internals of a few.\n",
    "    - Today: $k$-nearest neighbors and decision trees.\n",
    "    - Lectures 22-23: Logistic regression (and, potentially, Na√Øve Bayes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326cc032",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the data üè•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221284bf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our first classification example will involve predicting whether or not a patient has diabetes, given other information about their health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32bb84",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "display_df(diabetes, cols=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20293b51",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 0 means no diabetes, 1 means yes diabetes.\n",
    "diabetes['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5900b683",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `'Glucose'` is measured in mg/dL (milligrams per deciliter); `'BMI'` is calculated as $\\text{BMI} = \\frac{\\text{weight (kg)}}{\\left[ \\text{height (m)} \\right]^2}$.<br>Let's start by using these two features to predict whether or not a patient has diabetes (`'Outcome'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e07ef",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But first, a train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0eefb4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(diabetes[['Glucose', 'BMI']], diabetes['Outcome'], random_state=1)\n",
    ")\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04dc62",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43373b3d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's visualize the relationship between `X_train` and `y_train`. There are three numeric variables at play here ‚Äì `'Glucose'`, `'BMI'`, and `'Outcome'` ‚Äì so we can use a 3D scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62200867",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "px.scatter_3d(X_train.assign(Outcome=y_train), \n",
    "              x='Glucose', y='BMI', z='Outcome', \n",
    "              title='Relationship between Glucose, BMI, and Diabetes',\n",
    "              width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd33a187",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since there are only two possible `'Outcome'`s, we can draw a 2D scatter plot of `'BMI'` vs. `'Glucose'` and color each point by `'Outcome'`. Below, <span style='color: orange'><b>class 0 (orange) is \"no diabetes\"</b></span> and <span style='color: blue'><b>class 1 (blue) is \"diabetes\"</b></span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43049b02",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = util.create_base_scatter(X_train, y_train)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d215ab",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Using this dataset, how can we classify whether someone new (not already in the dataset) has diabetes, given their `'Glucose'` and `'BMI'`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d7839e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Intuition**: If a new person's feature vector is <b><span style=\"color:blue\">close to the blue points</span></b>, we'll predict <b><span style=\"color:blue\">blue (diabetes)</span></b>; if they're <b><span style=\"color:orange\">close to the orange points</span></b>, we'll predict <b><span style=\"color:orange\">orange (no diabetes)</span></b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db7777",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classifier 1: $k$-nearest neighbors  üè°üè†\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4379ab4e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-nearest neighbors üè°üè†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204b651",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose we're given a new individual, $\\vec{x}_\\text{new} = \\begin{bmatrix} \\text{Glucose}_\\text{new} \\\\ \\text{BMI}_\\text{new} \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c313d9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The $k$-nearest neighbors classifier ($k$-NN for short) classifies $\\vec{x}_\\text{new}$ by:\n",
    "    1. Finding the $k$ **closest points** in the training set to $\\vec{x}_\\text{new}$.\n",
    "    1. Predicting that $\\vec{x}_\\text{new}$ belongs to the **most common class** among those $k$ closest points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f77d1",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0d1b2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Example: Suppose $k = 6$. If, among the 6 closest points to $\\vec{x}_\\text{new}$, there are <b><span style=\"color:blue\">4 blue</span></b> and <b><span style=\"color:orange\">2 orange</span></b> points, we'd predict <b><span style=\"color:blue\">blue (diabetes)</span></b>.\n",
    "<br><small>What if there are ties? Read [here](https://stats.stackexchange.com/questions/144718/how-does-scikit-learn-resolve-ties-in-the-knn-classification).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd91e366",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $k$ is a hyperparameter that should be chosen through cross-validation.<br><small>As we've seen in Homework 8 and 9, in the context of $k$-NN regression, smaller values of $k$ tend to overfit significantly.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05667fd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `KNeighborsClassifier` in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff2328",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edab3fc8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's fit a `KNeighborsClassifier` by using cross-validation to choose a value of $k$ from 1 through 50.<br><small>Note that `KNeighborsClassifier`s have several other hyperparameters. One of them is the metric used to measure distances; the default is the standard Euclidean ($L_2$) distance, e.g. $\\text{dist}(\\vec u, \\vec v) = \\sqrt{(u_1 - v_1)^2 + (u_2 - v_2)^2 + ... + (u_d - v_d)^2}$.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e59e8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid = {'n_neighbors': range(1, 51)}\n",
    ")\n",
    "model_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09188cab",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_knn.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32769bca",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Cross-validation chose $k = 28$. With the resulting model, we can make predictions using the `predict` method, just like with regressors.<br><small>Note that all of the work in making the prediction ‚Äì finding the 28 nearest neighbors, for instance ‚Äì is done when we call `predict`. \"Training\" does very little.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80510ff2",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# To know what reasonable values for 'Glucose' and 'BMI' might be, let's look at the plot again.\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6d523",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_knn.predict(pd.DataFrame([{\n",
    "    'Glucose': 125,\n",
    "    'BMI': 40\n",
    "}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0a3ef",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What does the resulting model **look like** üëÄ? Can we visualize it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c2de8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb82114",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **decision boundaries** of a classifier visualize the regions in the feature space that separate different predicted classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efe061f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The decision boundaries for `model_knn` are visualized below.<br><small>If a new person's feature vector lies in the <b><span style=\"color:blue\">blue region</span></b>, we'd predict they <b><span style=\"color:blue\">do have diabetes</span></b>, <b><span style=\"color:orange\">otherwise</span></b>, we'd predict <b><span style=\"color:orange\">they don't</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c8059",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.visualize_k(28, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ea56c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What would the decision boundaries look like if $k$ increased or decreased?<br><small>Play with the slider below to find out!</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a78a29",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4cc02",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if $k = n$, the number of points in the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de414e4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.visualize_k(576, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d89a629",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quantifying the performance of a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79eec87",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For regression models, our default evaluation metric was **mean squared error**.<br><small>Error is bad, so **lower** values indicate **better** model performance.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf2a5e9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The most common evaluation metric in classification is **accuracy**:\n",
    "\n",
    "    $$\\text{accuracy} = \\frac{\\text{# points classified correctly}}{\\text{# points}}$$\n",
    "    \n",
    "    Accuracy ranges from 0 to 1, i.e. 0% to 100%. **Higher** values indicate **better** model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a817de",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Equivalent to 75%.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3a2263",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is the default metric that the `score` method of a classifier computes, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21b04b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0650cb7",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# For future reference.\n",
    "test_scores = pd.Series()\n",
    "...\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c64e159",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Accuracy is **not** the only metric we care about, and can sometimes be misleading. More on this soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33037e0a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "### Activity\n",
    "    \n",
    "It seems that a $k$-NN classifier that uses $k = 1$ should achieve 100% training accuracy. Why **doesn't** the model defined below have 100% training accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd0fc3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ac18d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_k1 = KNeighborsClassifier(n_neighbors=1)\n",
    "model_k1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa5156",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training accuracy ‚Äì high, but not 100%.\n",
    "model_k1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2594f93",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Accuracy on test set is lower than when k = 28!\n",
    "model_k1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fba901",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_scores['knn with k = 1'] = model_k1.score(X_test, y_test)\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a89329",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "### Discussion\n",
    "    \n",
    "Why should we generally **standardize** features before using a $k$-NN classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e77a54",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.create_scaled_version(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da1232",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395187e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parametric vs. non-parametric models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a0194d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The $k$-nearest neighbors classifier is an example of a **non-parametric** machine learning method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a2fa87",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Linear regression, on the other hand, is **parametric**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f426c5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One intuitive difference:\n",
    "    - Once we train a linear regression model, we don't need to look at the training set to make predictions ‚Äì we just use the optimal parameters $w_0^*, w_1^*, ..., w_d^*$ we found.\n",
    "    - Once we train a $k$-NN model, we still need to look at the training set each time we want to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48439285",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Other differences between parametric and non-parametric models:\n",
    "\n",
    "| Parametric | Non-Parametric |\n",
    "| --- | --- |\n",
    "| There's a fixed set of parameters (weights/coefficients), $w_0^*, w_1^*, ..., w_d^*$ that we'll use for making predictions, and the number of parameters is independent of the training set size. | No fixed set of parameters; model complexity increases as the training set size increases. |\n",
    "| Parametric methods make assumptions about the shape of the data and/or its underlying probability distribution.<br><small>For instance, linear models assume a linear relationship between the features $X$ and target $\\vec{y}$.<br>There's a connection between the squared loss function and maximum likelihood estimation, too.</small> | Non-parametric methods make no assumptions about the shape of the data. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1996561a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classifier 2: Decision trees üéÑ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e7029",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision trees üéÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c905330",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose we're given a new individual, $\\vec{x}_\\text{new} = \\begin{bmatrix} \\text{Glucose}_\\text{new} \\\\ \\text{BMI}_\\text{new} \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ea6527",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The decision tree classifier classifies $\\vec{x}_\\text{new}$ by:\n",
    "    1. Asking a series of yes/no questions about $\\text{Glucose}_\\text{new}$ and $\\text{BMI}_\\text{new}$, e.g.:\n",
    "    <br>\n",
    "    <center>Is $\\text{Glucose}_\\text{new} \\leq 129.5$?<br>If so, is $\\text{BMI}_\\text{new} \\leq 26.3$?\n",
    "    <br>If not, is $\\text{BMI}_\\text{new} \\leq 29.95$?<br>$\\vdots$</center>\n",
    "    2. Once it runs out of questions to ask, it predicts that $\\vec{x}_\\text{new}$ belongs to the **most common class** among training set points that had the same answers as $\\vec{x}_\\text{new}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7849f544",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Visually, a fit decision tree may look like:\n",
    "\n",
    "<center><img src=\"imgs/example-dt.png\" width=500</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c6a9f0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Decision trees are also **non-parametric**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd9f690",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `DecisionTreeClassifier` in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626921a8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf31e969",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's fit a `DecisionTreeClassifier`.<br><small>One of the main hyperparameters is `max_depth`, the number of questions to ask before making a prediction. Typically, we fit this with cross-validation, but for now we'll hard-code it.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f9f96",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(max_depth=3)\n",
    "model_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e796ba04",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The decision tree achieves a slightly higher test set accuracy than the cross-validated $k$-NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384b54e0",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9536e90d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_scores['decision tree with depth = 3'] = model_tree.score(X_test, y_test)\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ca33d4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But what does it **look like**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84db425",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision boundaries for a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fc53f3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_decision_boundary(model_tree, X_train, y_train, title='Decision Boundary for a Tree of Depth 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713f602f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Observe that the decision boundaries ‚Äì at least when we set `max_depth` to 3 ‚Äì look less \"jagged\" than with the $k$-NN classifier.<br><small>Decision trees partition the feature space into rectangles.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6ae9b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef8c3fb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our fit decision tree is like a \"flowchart\", made up of a series of questions.<br><small>It turns out `sklearn` provides us with a convenient way of visualizing this flowchart.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f5edc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As before, <span style='color: orange'><b>orange is \"no diabetes\"</b></span> and <span style='color: blue'><b>blue  is \"diabetes\"</b></span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd360d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_diabetes_decision_tree(model_tree, X_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b45d5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To **classify a new data point**, we start at the top and answer the first question (i.e. \"Glucose <= 129.5\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff12dab",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If the answer is \"**Yes**\", we move to the **left** branch, otherwise we move to the right branch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354fdd80",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We repeat this process until we end up at a leaf node, at which point we predict the most common class in that node.<br><small>Note that each node has a `value` attribute, which describes the number of **training** individuals of each class that fell in that node.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e81d52",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train[X_train[X_train['Glucose'] <= 129.5].index].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba20f2c9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Increasing tree depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3346104f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One of the many hyperparameters we can tune is tree depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5aacd6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What happens to the decision boundary of the resulting classifier if we increase `max_depth`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397aeef",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "interact(lambda depth: util.visualize_depth(depth, X_train, y_train), depth=(1, 51));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d8779",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- What happens to the flowchart representation of the resulting classifier if we increase `max_depth`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65149f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# By default, there is pre-specified maximum depth.\n",
    "# The training algorithm keeps \n",
    "model_tree_no_max = DecisionTreeClassifier()\n",
    "model_tree_no_max.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1644426",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_diabetes_decision_tree(model_tree_no_max, X_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d9b17",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The tree is **extremely overfit** to the training set, and very deep!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf219a6",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training accuracy. This number should look familiar!\n",
    "model_tree_no_max.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4247cae",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_tree_no_max.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e6217",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Worse test set performance than when we used max_depth = 3!\n",
    "test_scores['decision tree with no specified max depth'] = model_tree_no_max.score(X_test, y_test)\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615b5de",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "### Activity\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center><img src=\"imgs/chicken-class.png\" width=1200></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b83cc94",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classifier evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00097fc5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outcomes in binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02db002",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When performing **binary** classification, there are four possible outcomes.<br><small>Note: A \"positive prediction\" is a prediction of 1, and a \"negative prediction\" is a prediction of 0.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d451d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "|Outcome of Prediction|Definition|True Class|\n",
    "|---|---|---|\n",
    "|**True** positive (TP) ‚úÖ|The predictor **correctly** predicts the positive class.|P|\n",
    "|False negative (FN) ‚ùå|The predictor incorrectly predicts the negative class.|P|\n",
    "|**True** negative (TN) ‚úÖ|The predictor **correctly** predicts the negative class.|N|\n",
    "|False positive (FP) ‚ùå|The predictor incorrectly predicts the positive class.|N|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb29e271",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We typically organize the four quantities above into a **confusion matrix**.\n",
    "\n",
    "| | Predicted Negative | Predicted Positive |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | TN ‚úÖ | FP ‚ùå |\n",
    "| **Actually Positive** | FN ‚ùå | TP ‚úÖ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c33ff3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that in the four acronyms ‚Äì TP, FN, TN, FP ‚Äì the **first letter** is whether the prediction is correct, and the **second letter** is what the prediction is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2700f7fa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Depending on the situation, false negatives may be worse than false positives (or vice versa!).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde16cd0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Accuracy of COVID tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a7b10",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The results of 100 Michigan Medicine COVID tests are given below.\n",
    "\n",
    "| | Predicted Negative | Predicted Positive |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | TN = 90 ‚úÖ | FP = 1 ‚ùå |\n",
    "| **Actually Positive** | FN = 8 ‚ùå | TP = 1 ‚úÖ |\n",
    "<center><i><small>Michigan Medicine test results</small></i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0a5c73",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ü§î **Question:** What is the accuracy of the test?\n",
    "\n",
    "$$\n",
    "\\text{accuracy} = \\frac{\\text{# points classified correctly}}{\\text{# points}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf075a5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **üôã Answer:** $$\\text{accuracy} = \\frac{TP + TN}{TP + FP + FN + TN} = \\frac{1 + 90}{100} = 0.91$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c294b4b7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Followup:** At first, the test seems good. But, suppose we build a classifier that predicts that **nobody has COVID**. What would its accuracy be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ba7485",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer to followup:** Also 0.91! There is severe **class imbalance** in the dataset, meaning that most of the data points are in the same class (no COVID). **Accuracy doesn't tell the full story!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e961a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall\n",
    "\n",
    "| | Predicted Negative | Predicted Positive |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | TN = 90 ‚úÖ | FP = 1 ‚ùå |\n",
    "| <span style='color:orange'><b>Actually Positive</b></span> | <span style='color:orange'>FN = 8</span> ‚ùå | <span style='color:orange'>TP = 1</span> ‚úÖ |\n",
    "\n",
    "<center><i><small>Michigan Medicine test results</small></i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef9b2bc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ü§î **Question:** What proportion of individuals who actually have COVID did the test **identify**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f983d5cf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **üôã Answer:** $\\frac{1}{1 + 8} = \\frac{1}{9} \\approx 0.11$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27e46b8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- More generally, the **recall** of a binary classifier is the proportion of <span style='color:orange'><b>actually positive instances</b></span> that are correctly classified. We'd like this number to be as close to 1 (100%) as possible.\n",
    "\n",
    "$$\\text{recall} = \\frac{TP}{\\text{# actually positive}} = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c8865",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To compute recall, look at the <span style='color:orange'><b>bottom (positive) row</b></span> of the above confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d03360b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall isn't everything, either!\n",
    "\n",
    "$$\\text{recall} = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c4754c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ü§î **Question:** Can you design a \"COVID test\" with perfect recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59f74a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **üôã Answer:** Yes ‚Äì **just predict that everyone has COVID!**\n",
    "\n",
    "| | Predicted Negative | Predicted Positive |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | TN = 0 ‚úÖ | FP = 91 ‚ùå |\n",
    "| <span style='color:orange'><b>Actually Positive</b></span> | <span style='color:orange'>FN = 0</span> ‚ùå | <span style='color:orange'>TP = 9</span> ‚úÖ |\n",
    "\n",
    "<center><i><small>everyone-has-COVID classifier</small></i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ef10a1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{recall} = \\frac{TP}{TP + FN} = \\frac{9}{9 + 0} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86091881",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Like accuracy, recall on its own is not a perfect metric. Even though the classifier we just created has perfect recall, it has 91 false positives!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7243ea36",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision\n",
    "\n",
    "| | Predicted Negative | <span style='color:orange'>Predicted Positive</span> |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | TN = 0 ‚úÖ | <span style='color:orange'>FP = 91</span> ‚ùå |\n",
    "| **Actually Positive** | FN = 0 ‚ùå | <span style='color:orange'>TP = 9</span> ‚úÖ |\n",
    "\n",
    "<center><i><small>everyone-has-COVID classifier</small></i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54440e75",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **precision** of a binary classifier is the proportion of <span style='color:orange'><b>predicted positive instances</b></span> that are correctly classified. We'd like this number to be as close to 1 (100%) as possible.\n",
    "\n",
    "$$\\text{precision} = \\frac{TP}{\\text{# predicted positive}} = \\frac{TP}{TP + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e570b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To compute precision, look at the <span style='color:orange'><b>right (positive) column</b></span> of the above confusion matrix.<br><small>**Tip:** A good way to remember the difference between precision and recall is that in the denominator for üÖøÔ∏èrecision, both terms have üÖøÔ∏è in them (TP and FP).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd45fdcc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that the \"everyone-has-COVID\" classifier has perfect recall, but a precision of $\\frac{9}{9 + 91} = 0.09$, which is quite low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342ab18f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- üö® **Key idea:** There is a \"tradeoff\" between precision and recall. Ideally, you want both to be high. For a particular prediction task, one may be important than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6620db",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision and recall\n",
    "\n",
    "<center><img src=\"imgs/Precisionrecall.svg.png\" width=30%></center>\n",
    "\n",
    "<center>(<a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\">source</a>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff18633",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "### Discussion\n",
    "    \n",
    "$$\\text{precision} = \\frac{TP}{TP + FP} \\: \\: \\: \\:  \\: \\: \\: \\: \\text{recall} = \\frac{TP}{TP + FN}$$\n",
    "    \n",
    "- When might high **precision** be more important than high recall?\n",
    "- When might high **recall** be more important than high precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af413d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Activity</h3>\n",
    "\n",
    "\n",
    "Consider the confusion matrix shown below.\n",
    "\n",
    "| | Predicted Negative | Predicted Positive |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | TN = 22 ‚úÖ | FP = 2 ‚ùå |\n",
    "| **Actually Positive** | FN = 23 ‚ùå | TP = 18 ‚úÖ |\n",
    "\n",
    "What is the accuracy of the above classifier? The precision? The recall?\n",
    "\n",
    "<br>\n",
    "\n",
    "After calculating all three on your own, click below to see the answers.\n",
    "\n",
    "<details>\n",
    "    <summary><b>üëâ Accuracy</b></summary>\n",
    "    (22 + 18) / (22 + 2 + 23 + 18) = 40 / 65\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary><b>üëâ Precision</b></summary>\n",
    "    18 / (18 + 2) = 9 / 10\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary><b>üëâ Recall</b></summary>\n",
    "    18 / (18 + 23) = 18 / 41\n",
    "</details>    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582d61ea",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "#### Reference Slide\n",
    "\n",
    "### Combining precision and recall\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7188a78a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- If we care equally about a model's precision $PR$ and recall $RE$, we can combine the two using a single metric called the **F1-score**:\n",
    "\n",
    "$$\\text{F1-score} = \\text{harmonic mean}(PR, RE) = 2\\frac{PR \\cdot RE}{PR + RE}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ca27c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Both F1-score and accuracy are overall measures of a binary classifier's performance. But remember, accuracy is misleading in the presence of class imbalance, and doesn't take into account the kinds of errors the classifier makes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5a8bc4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "#### Reference Slide\n",
    "\n",
    "### Other evaluation metrics for binary classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e847fa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- We just scratched the surface! This [excellent table from Wikipedia](https://en.wikipedia.org/wiki/Template:Diagnostic_testing_diagram) summarizes the many other metrics that exist.\n",
    "\n",
    "<center><img src='imgs/wiki-table.png' width=75%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d482fdfc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- If you're interested in exploring further, a good next metric to look at is **true negative rate (i.e. specificity)**, which is the analogue of recall for true negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed2770",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiclass classification üêß\n",
    "\n",
    "<center><img src=\"imgs/lter_penguins.png\" width=800>\n",
    "<i><a href=\"https://github.com/allisonhorst/palmerpenguins/blob/main/README.md\">Artwork by @allison_horst</a></i>\n",
    "\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "To illustrate multiclass classification, we'll revisit the Palmer Penguins dataset we saw earlier in the semester."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72689b62",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From binary to multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14595efc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In binary classification, there are only two possible classes, typically either 0 or 1.\n",
    "\n",
    "$$y_i \\in \\{0, 1\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82eb802",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In multiclass classification, there can be any finite number of classes, or **labels**. They need not be numbers, either.\n",
    "\n",
    "$$y_i \\in \\{ \\text{Adelie}, \\text{Chinstrap}, \\text{Gentoo} \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa615c7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the data üêß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b6389",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "penguins = sns.load_dataset('penguins').dropna().reset_index(drop=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(penguins[['bill_length_mm', 'body_mass_g', 'bill_depth_mm']], \n",
    "                                                    penguins['species'], \n",
    "                                                    random_state=26)\n",
    "display(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f13860",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Here, each row corresponds to a single penguin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ab42e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are three `'species'` of penguin: Adelie, Chinstrap, and Gentoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f665a79",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705b12e7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: Suppose our goal is to predict the `'species'` of a penguin, given other information.<br> What accuracy would the best \"constant\" classifier achieve on this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe3ae9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fc490c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Visually, it seems that the `'species'` are penguins are well separated based on their physical characteristics (`'bill_depth_mm'`, `'bill_length_mm'`, and `'body_mass_g'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dce0f9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.penguin_scatter_3d(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec136e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For simplicity, we'll work with just two features: `'bill_length_mm'` and `'body_mass_g'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46015ab",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.penguin_scatter_2d(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a162a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classifier 1: $k$-nearest neighbors üè°üè†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b540f71",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's use the default of $k = 5$.<br><small>Of course, in practice, we _should_ cross-validate.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7fe49",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn.fit(X_train.iloc[:, :-1], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126fd9d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are now three colors in the decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b1b7d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.penguin_decision_boundary(model_knn, X_train, y_train, title=\"k-NN Decision Boundary when k = 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24644c2a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### If distances matter, standardize!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf732f5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The decision boundary on the previous slide looked extremely jagged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7229cfcb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since the scales of the features are very different, it's a good idea to first standardize both features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd5cb5",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model_knn_standardized = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=5))\n",
    "model_knn_standardized.fit(X_train.iloc[:, :-1], y_train)\n",
    "util.penguin_decision_boundary(model_knn_standardized, X_train, y_train, title=\"k-NN Decision Boundary when k = 5 and with Standardization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a23ee",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classifier 2: Decision trees üéÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5db87b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's fix `max_depth=3` so that we can visualize the resulting tree.<br><small>Again, in practice, we _should_ cross-validate.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909dc250",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(max_depth=2)\n",
    "model_tree.fit(X_train.iloc[:, :-1], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79553314",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that colors below don't directly match the colors in the scatter plot earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399d380",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.penguin_decision_boundary(model_tree, X_train.iloc[:, :-1], y_train, title=\"Decision Boundary for a Decision Tree of Depth 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1d585",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_penguin_decision_tree(model_tree, X_train);"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
