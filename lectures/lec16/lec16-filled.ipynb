{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff241e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from lec_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a215dd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\" markdown=\"1\">\n",
    "\n",
    "#### Lecture 16\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "### EECS 398: Practical Data Science, Spring 2025\n",
    "\n",
    "<small><a style=\"text-decoration: none\" href=\"https://practicaldsc.org\">practicaldsc.org</a> ‚Ä¢ <a style=\"text-decoration: none\" href=\"https://github.com/practicaldsc/sp25\">github.com/practicaldsc/sp25</a> ‚Ä¢ üì£ See latest announcements [**here on Ed**](https://edstem.org/us/courses/78535/discussion/6647877) </small>\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8af5c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda üìÜ\n",
    "\n",
    "- Recap: Multiple linear regression.\n",
    "- Feature engineering.\n",
    "- Numerical-to-numerical transformations üß¨.\n",
    "- The modeling recipe, revisited.\n",
    "- `StandardScaler` and standardized regression coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d5a660",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c70db7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap: Multiple linear regression\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c2c7ca",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The general problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502eee2c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  We have $n$ data points, $\\left({ \\vec x_1}, {y_1}\\right), \\left({ \\vec x_2}, {y_2}\\right),  \\ldots, \\left({ \\vec x_n}, {y_n}\\right)$,\n",
    "where each $ \\vec x_i$ is a feature vector of $d$ features:\n",
    "$${\\vec{x_i}} = \\begin{bmatrix} \n",
    "{x^{(1)}_i} \\\\ {x^{(2)}_i} \\\\ \\vdots \\\\ {x^{(d)}_i}\n",
    "\\end{bmatrix}$$\t   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31b043",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  We want to find a good linear hypothesis function:\n",
    "\n",
    "$$H({\\vec x_i}) = w_0 + w_1 { x_i^{(1)}} + w_2 { x_i^{(2)}} + \\ldots + w_d { x_i^{(d)}} = \\vec w \\cdot \\text{Aug}({ \\vec x_i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e593f6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Specifically, we want to find the optimal parameters, $w_0^*$, $w_1^*$, ..., $w_d^*$ that minimize mean squared error:\n",
    "\n",
    "$$\\begin{align*} R_\\text{sq}(\\vec w) &= \\frac{1}{n} \\sum_{i = 1}^n (y_i - H(\\vec x_i))^2 \\\\ &=\n",
    "\\frac{1}{n} \\sum_{i = 1}^n \\left( y_i - (w_0 + w_1 { x_i^{(1)}} + w_2 { x_i^{(2)}} + \\ldots + w_d { x_i^{(d)}})\\right)^2 \n",
    "\\\\ &= \\frac{1}{n} \\sum_{i = 1}^n \\left(y_i - \\text{Aug}(\\vec x_i) \\cdot \\vec{w} \\right)^2 \\\\ &= \\frac{1}{n} \\lVert \\vec y - X \\vec w \\rVert^2 \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398160cc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The general solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d56f3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Define the **design matrix** $ X \\in \\mathbb{R}^{n \\times (d + 1)}$ and **observation vector** $\\vec y \\in \\mathbb{R}^n$:\n",
    "\n",
    "$${ X=  \\begin{bmatrix}  \n",
    "{1} & { x^{(1)}_1} & { x^{(2)}_1} & \\dots & { x^{(d)}_1} \\\\\\\\\n",
    "{ 1} & { x^{(1)}_2} & { x^{(2)}_2} & \\dots & { x^{(d)}_2} \\\\\\\\\n",
    "\\vdots & \\vdots & \\vdots  &  & \\vdots \\\\\\\\\n",
    "{ 1} & { x^{(1)}_n} & { x^{(2)}_n} & \\dots & { x^{(d)}_n}\n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "       \\text{Aug}({\\vec{x_1}})^T \\\\\\\\\n",
    "       \\text{Aug}({\\vec{x_2}})^T \\\\\\\\\n",
    "       \\vdots \\\\\\\\\n",
    "       \\text{Aug}({\\vec{x_n}})^T\n",
    "   \\end{bmatrix}} \\qquad { \\vec y = \\begin{bmatrix} { y_1} \\\\ { y_2} \\\\ \\vdots \\\\ { y_n} \\end{bmatrix}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb6fcf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Then, solve the **normal equations** to find the optimal parameter vector, $\\vec{w}^*$:\n",
    "\n",
    "$$X^TX \\vec w^* = X^T \\vec y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643bbccd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The $\\vec w^*$ that satisfies the equations above minimizes mean squared error, $R_\\text{sq}(\\vec w)$, so use this $\\vec w^*$ to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ce9ae",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Once $\\vec w^*$ is found:\n",
    "    - $X \\vec w^*$ is a hypothesis vector of predicted $y$-values for the entire dataset.\n",
    "    - $$H^*(\\vec x_i) = w_0^* + w_1^* x_i^{(1)} + w_2^* x_i^{(2)} + ... + w_d^* x_i^{(d)} = \\vec w^* \\text{Aug}(\\vec x_i)$$ returns the predicted $y$-value for just the input $\\vec x_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb67795",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $X^TX$ is invertible, then:\n",
    "\n",
    "$$\\boxed{\\vec w^* = (X^TX)^{-1}X^T \\vec y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b89746",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `sklearn` can compute $\\vec w^*$ automatically, as we will see again shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278eaf6f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature engineering ‚öôÔ∏è\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac050b76",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The goal of feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f340b936",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Feature engineering** is the act of finding **transformations** that transform data into effective **quantitative variables**.<br><small>Put simply: feature engineering is creating new features using existing features.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325d1db9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example**: One hot encoding.\n",
    "\n",
    "<center><img src=\"imgs/one-hot.png\" width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d4637",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example**: Numerical-to-numerical transformations.\n",
    "\n",
    "<center><img src=\"imgs/quant-scale.png\" width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33fda13",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef0a329",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One hot encoding is a transformation that turns a categorical feature into several binary features.\n",
    "\n",
    "<center><img src=\"imgs/one-hot.png\" width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a9e6a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose a column has $N$ unique values, $A_1$, $A_2$, ..., $A_N$. For each unique value $A_i$, we define the following **feature function**:\n",
    "\n",
    "$$\\phi_i(x) = \\left\\{\\begin{array}{ll}1 & {\\rm if\\ } x == A_i \\\\ 0 &  {\\rm if\\ } x\\neq A_i \\\\ \\end{array}\\right. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1259dc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that 1 means \"yes\" and 0 means \"no\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15af25a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One hot encoding is also called \"dummy encoding\", and $\\phi_i(x)$ may also be referred to as an \"indicator variable\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6267c1b4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Run the cells below to set up the next slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b7d572",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/commute-times.csv')\n",
    "df['day_of_month'] = pd.to_datetime(df['date']).dt.day\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87197905",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: One hot encoding `'day'`\n",
    "\n",
    "- For each unique value of `'day'` in our dataset, we must create a column for just that `'day'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a681793",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7116228",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['day'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4da906",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df['day'] == 'Tue').astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f2d0e9",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for val in df['day'].unique():\n",
    "    df[f'day == {val}'] = (df['day'] == val).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d848473",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.loc[:, df.columns.str.contains('day')] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554bee16",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `'day'` as a feature, along with `'departure_hour'` and `'day_of_month'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca1d976",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now that we've converted `'day'` to a numerical variable, we can use it as input in a regression model. Here's the model we'll try to fit:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f9ba1d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\begin{align*}\\text{pred. commute time}_i = w_0 &+ w_1 \\cdot \\text{departure hour}_i \\\\ &+ w_2 \\cdot \\text{day of month}_i \\\\ &+ w_3 \\cdot \\text{day$_i$ == Mon} \\\\ \n",
    "&+ w_4 \\cdot \\text{day$_i$ == Tue} \\\\ \n",
    "&+ w_5 \\cdot \\text{day$_i$ == Wed} \\\\ \n",
    "&+ w_6 \\cdot \\text{day$_i$ == Thu} \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02950820",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Subtlety**: Since there are only 5 values of `'day'`, we don't need to include $\\text{day}_i \\text{ == Fri}$ as a feature. We know it's Friday if $\\text{day}_i \\text{ == Mon}$, $\\text{day}_i \\text{ == Tue}$, ... are all 0.<br><small>More on this next class!</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107eaad",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_for_ohe = df[['departure_hour', \n",
    "                'day_of_month',\n",
    "                'day == Mon',\n",
    "                'day == Tue',\n",
    "                'day == Wed',\n",
    "                'day == Thu']]\n",
    "X_for_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a8b41",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_with_ohe = LinearRegression()\n",
    "model_with_ohe.fit(X=X_for_ohe, y=df['minutes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa059765",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The following cell gives us our $w^*$s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae72fe9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_with_ohe.intercept_, model_with_ohe.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e379d27",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Thus, our trained linear model to predict commute time given `'departure_hour'`, `'day_of_month'`, and `'day'` (Mon, Tue, Wed, or Thu) is:\n",
    "\n",
    "$$\\begin{align*}\\text{pred. commute time}_i = 134 &- 8.42 \\cdot \\text{departure hour}_i \\\\ &- 0.03 \\cdot \\text{day of month}_i \\\\ \n",
    "&+ 5.09 \\cdot \\text{day$_i$ == Mon} \\\\ \n",
    "&+ 16.38 \\cdot \\text{day$_i$ == Tue} \\\\ \n",
    "&+ 5.12 \\cdot \\text{day$_i$ == Wed} \\\\ \n",
    "&+ 11.5 \\cdot \\text{day$_i$ == Thu} \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ed4bb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing our latest model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd94687",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our trained linear model to predict commute time given `'departure_hour'`, `'day_of_month'`, and `'day'` (Mon, Tue, Wed, or Thu) is:\n",
    "\n",
    "$$\\begin{align*}\\text{pred. commute time}_i = 134 &- 8.42 \\cdot \\text{departure hour}_i \\\\ &- 0.03 \\cdot \\text{day of month}_i \\\\ \n",
    "&+ 5.09 \\cdot \\text{day$_i$ == Mon} \\\\ \n",
    "&+ 16.38 \\cdot \\text{day$_i$ == Tue} \\\\ \n",
    "&+ 5.12 \\cdot \\text{day$_i$ == Wed} \\\\ \n",
    "&+ 11.5 \\cdot \\text{day$_i$ == Thu} \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ce6db",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since we have 6 features here, we'd need 7 dimensions to graph our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9802fd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But, as we see in Homework 7, Question 5, our model is really a collection of **five parallel planes** in 3D, all with slightly different $z$-intercepts!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1535b6de",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- If we want to visualize in 2D, we need to pick a single feature to place on the $x$-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cec69d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['departure_hour'], y=df['minutes'], \n",
    "                         mode='markers', name='Original Data'))\n",
    "fig.add_trace(go.Scatter(x=df['departure_hour'], y=model_with_ohe.predict(X_for_ohe), \n",
    "                         mode='markers', name='Predicted Commute Times using Departure Hour, <br>Day of Month, and Day of Week'))\n",
    "fig.update_layout(showlegend=True, title='Commute Time vs. Departure Hour',\n",
    "                  xaxis_title='Departure Hour', yaxis_title='Minutes', width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d12f83",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Despite being a linear model, why **doesn't** this model **look** like a straight line?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74f498a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Run the cells below to set up the next slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546db384",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e7d7b2",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Multiple linear regression model.\n",
    "model_multiple = LinearRegression()\n",
    "model_multiple.fit(X=df[['departure_hour', 'day_of_month']], y=df['minutes'])\n",
    "mse_dict = {}\n",
    "mse_dict['departure_hour + day_of_month'] = mean_squared_error(df['minutes'], model_multiple.predict(df[['departure_hour', 'day_of_month']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb52396",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Simple linear model.\n",
    "model_simple = LinearRegression()\n",
    "model_simple.fit(X=df[['departure_hour']], y=df['minutes'])\n",
    "mse_dict['departure_hour'] = mean_squared_error(df['minutes'], model_simple.predict(df[['departure_hour']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3dcf44",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Constant model.\n",
    "model_constant = df['minutes'].mean()\n",
    "mse_dict['constant'] = mean_squared_error(df['minutes'], np.ones(df.shape[0]) * model_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbbcc38",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing our latest model to earlier models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c556c973",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's see how the inclusion of the day of the week impacts the quality of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7bdffb",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mse_dict['departure_hour + day_of_month + ohe day'] = mean_squared_error(\n",
    "    df['minutes'],\n",
    "    model_with_ohe.predict(X_for_ohe)\n",
    ")\n",
    "pd.Series(mse_dict).plot(kind='barh', title='Mean Squared Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d37cab",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Adding the day of the week decreased our MSE **significantly**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43ea6d6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4285b279",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42889dfa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We've one hot encoded `'day'`, but it required a `for`-loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95565b25",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Is there a way we could have encoded it without a `for`-loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a297903b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Yes, using `sklearn.preprocessing`'s `OneHotEncoder`. More on this soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9da02c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a4a1f5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numerical-to-numerical transformations üß¨\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aadb384",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Horsepower üöó"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabe031",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The following dataset, built into the `seaborn` plotting library, contains various information about (older) cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd189da",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "mpg = sns.load_dataset('mpg').dropna()\n",
    "mpg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ebdbc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We really do mean old:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d88cf31",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mpg['model_year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764af37",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's investigate the relationship between `'horsepower'` and `'mpg'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b44c1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The relationship between `'horsepower'` and `'mpg'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f6394",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "px.scatter(mpg, x='horsepower', y='mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ed5481",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It appears that there is a negative association between `'horsepower'` and `'mpg'`, though it's not quite linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee89cbf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's try and fit a simple linear model that uses `'horsepower'` to predict `'mpg'` and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d051f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting `'mpg'` using `'horsepower'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ff81b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "car_model = LinearRegression()\n",
    "car_model.fit(mpg[['horsepower']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf6e6c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What do our predictions look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3adc95",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hp_points = pd.DataFrame({'horsepower': [25, 225]})\n",
    "fig = px.scatter(mpg, x='horsepower', y='mpg')\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=hp_points['horsepower'],\n",
    "    y=car_model.predict(hp_points),\n",
    "    mode='lines',\n",
    "    name='Predicted MPG using Horsepower'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eae214b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our regression line doesn't capture the curvature in the relationship between `'horsepower'` and `'mpg'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02383827",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# As a baseline:\n",
    "mean_squared_error(mpg['mpg'], car_model.predict(mpg[['horsepower']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6655db",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear in the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d67702",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  **Using linear regression**, we can fit hypothesis functions like:\n",
    "    $$\n",
    "    H(x_i) = w_0 + w_1x_i+w_2x_i^2\n",
    "    \\qquad \\qquad \n",
    "    H(\\vec x_i) = w_1e^{-x_i^{{(1)}^2}} + w_2 \\cos(x_i^{(2)}+\\pi) +w_3 \\frac{\\log 2x_i^{(3)}}{x_i^{(2)}}\n",
    "    $$\n",
    "    \n",
    "    <br>\n",
    "    <small>This includes all polynomials, for example. These are all <b>linear combinations of (just) features</b>.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4ef65",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For any of the above examples, we **could** express our model as $\\vec w \\cdot \\text{Aug} (\\vec x_i)$, for some carefully chosen feature vector $\\vec x_i$, <br>and that's all that `LinearRegression` in `sklearn` needs.<br><small>What we put in the `X` argument to `model.fit` is up to us!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c153502",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  Using linear regression, we **can't** fit hypothesis functions like:\n",
    "    $$\n",
    "    H(x_i) = w_0 + e^{w_1 x_i}\n",
    "    \\qquad \\qquad \n",
    "    H(\\vec x_i) = w_0 + \\sin (w_1 x_i^{(1)} + w_2 x_i^{(2)})\n",
    "    $$\n",
    "    <br><small>These are <b>not</b> linear combinations of just features.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d361dc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  We can have any number of parameters, as long as our hypothesis function is **linear in the parameters**, or linear when we think of it as a function of the parameters.\n",
    "\n",
    "$$H(\\vec x_i) = w_0 + w_1 f_1(\\vec x_i) + w_2 f_2(\\vec x_i) + ... + w_d f_d(\\vec x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bcd833",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linearization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec2fcb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The [Tukey Mosteller Bulge Diagram](https://sites.stat.washington.edu/pds/stat423/Documents/LectureNotes/notes.423.ch4.pdf) helps us pick which **numerical-to-numerical** transformations to apply to data in order to **linearize** it.<br><small>Alternative interpretation: it helps us determine which features to create.</small>\n",
    "\n",
    "<center><img src=\"imgs/bulge.png\" width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b5402",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Why**? We're working with linear models. The more linear our data looks in terms of its features, the better we'll able to model the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc94e09",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a5879a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Here, the bottom-left quadrant appears to match the shape of the scatter plot between `'horsepower'` and `'mpg'` the best ‚Äì let's try taking the `log` of `'horsepower'` (the $x$ variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bdb588",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mpg['log hp'] = np.log(mpg['horsepower'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19acfc6b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What does our data look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225e946",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "px.scatter(mpg, x='log hp', y='mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c99e94",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting `'mpg'` using `log('horsepower')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8892c9a7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's fit another linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f9e3b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "car_model_log = LinearRegression()\n",
    "car_model_log.fit(mpg[['log hp']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92374a5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that implicitly, we defined the following design matrix:\n",
    "\n",
    "$$X = \\begin{bmatrix} 1 & \\log(x_1) \\\\ 1 & \\log(x_2) \\\\ \\vdots & \\vdots \\\\ 1 & \\log(x_n) \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5dd11a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What do our predictions look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f4031b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(mpg, x='log hp', y='mpg')\n",
    "log_hp_points = pd.DataFrame({'log hp': [3.7, 5.5]})\n",
    "fig = px.scatter(mpg, x='log hp', y='mpg')\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=log_hp_points['log hp'],\n",
    "    y=car_model_log.predict(log_hp_points),\n",
    "    mode='lines',\n",
    "    name='Predicted MPG using log(Horsepower)'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e41bf2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The fit looks a bit better! How about the MSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756bb4b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Using log hp:\n",
    "mean_squared_error(mpg['mpg'], car_model_log.predict(mpg[['log hp']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467c5ff",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Using hp, from before:\n",
    "mean_squared_error(mpg['mpg'], car_model.predict(mpg[['horsepower']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06affbbe",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Also a bit better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3509f3dd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- What do our predictions look like on the original, non-transformed scatter plot? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03205fb4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(mpg, x='horsepower', y='mpg')\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=mpg['horsepower'], \n",
    "        y=car_model_log.intercept_ + car_model_log.coef_[0] * np.log(mpg['horsepower']),  \n",
    "        mode='markers', name='Predicted MPG using log(Horsepower)'\n",
    "    )\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c136ccc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our predictions that used $\\log(\\text{Horsepower})$ as an input don't fall on a straight line. We shouldn't expect them to; the orange dots come from:\n",
    "\n",
    "$$\\text{predicted MPG}_i = 108.70 - 18.582 \\cdot \\log(\\text{Horsepower}_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9fa320",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "car_model_log.intercept_, car_model_log.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5e8e7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "\n",
    "Which hypothesis function is **not** linear in the parameters?\n",
    "\n",
    "- A. $H(\\vec{x}_i) = w_1 (x_i^{(1)} x_i^{(2)}) + \\frac{w_2}{x_i^{(1)}} \\sin \\left( x_i^{(2)} \\right)$\n",
    "- B. $H(\\vec{x}_i) = 2^{w_1} x_i^{(1)}$\n",
    "- C. $H(\\vec{x}_i) = \\vec{w} \\cdot \\text{Aug}(\\vec{x}_i)$\n",
    "- D. $H(\\vec{x}_i) = w_1 \\cos (x_i^{(1)}) + w_2 2^{x_i^{(2)} \\log x_i^{(3)}}$\n",
    "- E. More than one of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11568c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do we fit hypothesis functions that aren't linear in the parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bcb0c4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  Suppose we want to fit the hypothesis function:\n",
    "\n",
    "$$H(x_i) = w_0 e^{w_1 x_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b5cd4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is **not** linear in terms of $w_0$ and $w_1$, so our results for linear regression don't apply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e223708",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  **Possible solution**: Try to transform the above equation so that it **is** linear in some other parameters, by applying an operation to both sides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b3e3a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- See the attached Reference Slide for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d1c3d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca7234",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "#### Reference Slide\n",
    "\n",
    "### Transformations\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c4550e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "$$H(x_i) = w_0 e^{w_1 x_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905e0536",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Suppose we take the $\\log$ of both sides of the equation.\n",
    "\n",
    "$$\\log H(x_i) = \\log (w_0 e^{w_1x_i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cc6d09",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Then, using properties of logarithms, we have:\n",
    "\n",
    "$$\\log H(x_i) = \\underbrace{\\log(w_0)}_{\\text{this is just a constant!}} + w_1 x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0371da4f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- **Solution**: Create a new hypothesis function, $T(x_i)$, with parameters $b_0$ and $b_1$, where $T(x_i) = b_0 + b_1 x_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af5f440",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "-  This hypothesis function is related to $H(x_i)$ by the relationship $T(x_i) = \\log H(x_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6a6a4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "-  $\\vec{b}$ is related to $\\vec{w}$ by $b_0 = \\log w_0$ and $b_1 = w_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d1492b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "-  Our new observation vector, $\\vec{z}$, is $\\begin{bmatrix} \\log y_1 \\\\ \\log y_2 \\\\ ... \\\\ \\log y_n \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5f684a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "-  $T(x_i) = b_0 + b_1x_i$ is linear in its parameters, $b_0$ and $b_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e17c82",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "-  Use the solution to the normal equations to find $\\vec{b}^*$, and the relationship between $\\vec{b}$ and $\\vec{w}$ to find $\\vec{w}^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76772df5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The modeling recipe, revisited\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dda2a0b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The original modeling recipe, from Lecture 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960cd176",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Choose a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed7103",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Choose a loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f34702f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Minimize average loss (empirical risk) to find optimal model parameters, $\\vec w^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c57145",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The updated modeling recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b14729",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "0. Create, or engineer, features to best reflect the \"meaning\" behind data.<br><small>Recently, we've done this with one hot encoding and numerical-to-numerical transformations.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e14fdca",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Choose a model.<br><small>Recently, we've used the simple/multiple linear regression model.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cb3f22",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Choose a loss function.<br><small>Recently, we've mostly used squared loss.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61271f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Minimize average loss (empirical risk) to find optimal model parameters, $\\vec{w}^*$.<br><small>Originally, we had to use calculus or linear algebra to minimize empirical risk, but more recently we've just used `model.fit`. This step is also called **fitting the model to the data**.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4bc390",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. Evaluate the performance of the model in relation to other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c7e51",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **We can do all of the above directly in `sklearn`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0325ed55",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `preprocessing` and `linear_model`s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c932a9e5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For the **feature engineering** step of the modeling pipeline, we will use `sklearn`'s [`preprocessing`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module.\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2555470d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For the **model creation** step of the modeling pipeline, we will use `sklearn`'s [`linear_model`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) module, as we've already seen. `linear_model.LinearRegression` is an example of an **estimator** class.\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95802d8f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformer classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a4604",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Transformers** take in \"raw\" data and output \"processed\" data. They are used for **creating features**.<br><small>These are not directly related to \"transformers\" in large language models and neural networks.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aceda19",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Transformers, like most relevant features of `sklearn`, are **classes**, not functions, meaning you need to instantiate them and call their methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ca382",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Today, we'll introduce one transformer class, `StandardScaler`. We'll look at how to write code to use it, and also discuss some of the underlying statistical nuances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b10110",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Next class, we'll learn about another transformer class - `OneHotEncoder` ‚Äì and we'll see how to chain transformers and estimators together into larger **Pipelines**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e77a67",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `StandardScaler` and standardized regression coefficients\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b15437",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting sales üìà"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30de70f3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To illustrate our first transformer class, we'll introduce a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85c940",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('data/sales.csv')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b0ad5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For each of 26 stores, we have:\n",
    "    -  net sales, \n",
    "    -  square feet, \n",
    "    -  inventory,\n",
    "    -  advertising expenditure, \n",
    "    -  district size, and\n",
    "    -  number of competing stores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c9187",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our goal is to predict `'net_sales'` as a function of other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17485db3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5b83d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990be606",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- No transformations are _needed_ to predict `'net_sales'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6906a0f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales_model = LinearRegression()\n",
    "sales_model.fit(X=sales.iloc[:, 1:], y=sales.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f5ab53",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose we're interested in learning **how** the various features impact `'net_sales'`, rather than just predicting `'net_sales'` for a new store. We'd then look at the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d8530",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4653f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame().assign(\n",
    "    column=sales.columns[1:],\n",
    "    original_coef=sales_model.coef_,\n",
    ").set_index('column')\n",
    "coefs.plot(kind='barh', title='Original Coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723676c0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312ff7a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1734a3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Thought experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7718f3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Consider the white point in the scatter plot below.\n",
    "\n",
    "<center><img src=\"imgs/std-example.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed274a8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Which class is it more \"similar\" to ‚Äì <b><span style=\"color:blue\">blue</span></b> or <b><span style=\"color:orange\">orange</span></b>?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc5a6e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Intuitively, the answer may be <b><span style=\"color:blue\">blue</span></b>, but take a close look at the scale of the axes!<br>The <b><span style=\"color:orange\">orange</span></b> point is much closer to the white point than the <b><span style=\"color:blue\">blue</span></b> points are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc628792",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d11416b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When we standardize two or more features, we bring them to the **same scale**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c36c181",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  Recall: to standardize a feature $x_1, x_2, ..., x_n$, we use the formula:\n",
    "    $$z(x_i) = \\frac{x_i - \\bar{x}}{\\sigma_x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad41019",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  Example: 1, 7, 7, 9.\n",
    "    -  Mean: $\\frac{1 + 7 + 7 + 9}{4} = \\frac{24}{4} = 6$.\n",
    "    -  Standard deviation:\n",
    "\n",
    "    $$\\text{SD} = \\sqrt{\\frac{1}{4} \\left( (1-6)^2 + (7-6)^2 + (7-6)^2 + (9-6)^2 \\right)} = \\sqrt{\\frac{1}{4} \\cdot 36} = 3$$\n",
    "    -  Standardized data: \n",
    "\n",
    "    $$1 \\mapsto \\frac{1-6}{3} = \\boxed{-\\frac{5}{3}} \\qquad 7 \\mapsto \\frac{7-6}{3} = \\boxed{\\frac{1}{3}} \\qquad 7 \\mapsto \\boxed{\\frac{1}{3}} \\qquad 9 \\mapsto \\frac{9-6}{3} = \\boxed{1}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a76e9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pre- and post- standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e10812",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Before** we standardize both axes:\n",
    "\n",
    "<center><img src=\"imgs/std-example.png\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9fbf0e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **After** we standardize both axes:\n",
    "\n",
    "<center><img src=\"imgs/std-example-2.png\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db5c81",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- After we standardize, our features are measured on the same scales, so **they can be compared directly**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc709b1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Which features are most \"important\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f923003",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  The most important feature is **not necessarily** the feature with largest magnitude coefficient, because different features may be on different scales.<br><small>But, it would be nice if the most important feature was the one with the largest magnitude coefficient!</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e86355",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coefs.plot(kind='barh', title='Original Coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32195727",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595135c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Here, `'inventory'` values are much larger than `'sq_ft'` values, which means that the coefficient for `'inventory'` will inherently be smaller, even if `'inventory'` is a more important feature than `'sq_ft'`.<br><small>Intuition: if the values themselves are larger, you need to multiply them by smaller coefficients to get the same predictions!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec69700",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solution**: If you care about the interpretability of the resulting coefficients, **standardize** each feature before performing regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac88487",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `StandardScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f405ccc5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `StandardScaler` **standardizes** data using the mean and standard deviation of the data.\n",
    "\n",
    "$$z(x_i) = \\frac{x_i - \\bar{x}}{\\sigma_x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d1e79",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- First, we need to import the relevant class from `sklearn.preprocessing`.<br><small>It's best practice to import just the relevant classes you need from `sklearn`.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16caf4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1dd64c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Like an estimator, we need to instantiate **and fit** our `OneHotEncoder` instsance before it can transform anything.<br><small>Here, \"fitting\" the transformer involves computing and saving the mean and SD of each column.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592543d4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881fb70f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Doesn't work! Need to fit first.\n",
    "stdscaler.transform(sales.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23f930",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This is like saying \"determine the mean and SD of each column in sales, \n",
    "# other than the 'net_sales' column\".\n",
    "stdscaler.fit(sales.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0cf1bd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now, we can standardize any dataset, using the mean and standard deviation of the columns in `sales.iloc[:, 1:]`. Typical usage is to fit transformer on a sample and use that already-fit transformer to transform future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a0ef81",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stdscaler.transform([[5, 300, 10, 15, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c0e7e6",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stdscaler.transform(sales.iloc[:, 1:].tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d5bc4c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can peek under the hood and see what it computed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41f48f0",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stdscaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ce77c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stdscaler.var_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa1902",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If needed, the `fit_transform` method will fit the transformer and then transform the data in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48115471",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a102ae",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_scaler.fit_transform(sales.iloc[:, 1:].tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6b70a7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why are the values above different from the values in `stdscaler.transform(sales.iloc[:, 1:].tail(5))`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93995b0d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpreting standardized regression coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f4f6c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now that we have a technique for standardizing the feature columns of `sales`, let's fit a new regression object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9da54b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales_model_std = LinearRegression()\n",
    "sales_model_std.fit(X=stdscaler.transform(sales.iloc[:, 1:]),\n",
    "                    y=sales.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc69daf7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's now look at the resulting coefficients, and compare them to the coefficients before we standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07752cfd",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame().assign(\n",
    "    column=sales.columns[1:],\n",
    "    original_coef=sales_model.coef_,\n",
    "    standardized_coef=sales_model_std.coef_\n",
    ").set_index('column').plot(kind='barh', barmode='group', title='Standardized and Original Coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c78401f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Did the performance of the resulting model change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d17ea2a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(sales.iloc[:, 0],\n",
    "                   sales_model.predict(sales.iloc[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea3614",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(sales.iloc[:, 0],\n",
    "                   sales_model_std.predict(stdscaler.transform(sales.iloc[:, 1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2bceb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **No!**<br><small>The span of the design matrix did not change, so the predictions did not change. It's just the coefficients that changed.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eec8add",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Key takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd333bc9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  The result of standardizing each feature (separately!) is that the units of each feature are on the same scale.\n",
    "    -  There's no need to standardize the outcome (`'net_sales'` here), since it's not being compared to anything.\n",
    "    - Also, we can't standardize the column of all 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a69281",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  Then, solve the normal equations. The resulting $w_0^*, w_1^*, \\ldots, w_d^*$ are called the **standardized regression coefficients**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbffabd3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-  Standardized regression coefficients can be directly compared to one another.<br>**Features with larger (absolute) standardized regression coefficients are most important to the model's predictions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f67c80",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As we saw on the previous slide, standardizing each feature **does not** change the MSE of the resulting hypothesis function!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235e8b1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `StandardScaler` summary\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `stdscaler = StandardScaler()` | z-score the data (no parameters) |\n",
    "|Fit the transformer| `stdscaler.fit(X)` | Compute the mean and SD of `X`|\n",
    "|Transform data in a dataset | `feat = stdscaler.transform(X_new)` | z-score `X_new` with mean and SD of `X`|\n",
    "|Fit and transform| `stdscaler.fit_transform(X)` | Compute the mean and SD of `X`, then z-score `X`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0043d109",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9056ce2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How does `OneHotEncoder` work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f5e18",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Even though we have a `StandardScaler` transformer object, to actually use standardize our features AND make predictions, we need to:\n",
    "    - Manually instantiate a `StandardScaler` object, and then `fit` it.\n",
    "    - Create a new design matrix by taking the result of calling `transform` on the `StandardScaler` object and concatenating other relevant numerical columns.\n",
    "    - Manually instantiate a `LinearRegression` object, and then `fit` it using the result of the above step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d51b1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As we build more and more sophisticated models, it will be challenging to keep track of all of these individual steps ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0367b731",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As such, we often build **Pipelines**."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
