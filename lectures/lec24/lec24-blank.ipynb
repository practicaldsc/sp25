{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cdd5de",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from lec_utils import *\n",
    "import lec24_util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f30a3e1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\" markdown=\"1\">\n",
    "\n",
    "#### Lecture 24\n",
    "\n",
    "# Clustering\n",
    "\n",
    "### EECS 398: Practical Data Science, Spring 2025\n",
    "\n",
    "<small><a style=\"text-decoration: none\" href=\"https://practicaldsc.org\">practicaldsc.org</a> â€¢ <a style=\"text-decoration: none\" href=\"https://github.com/practicaldsc/sp25\">github.com/practicaldsc/sp25</a> â€¢ ðŸ“£ See latest announcements [**here on Ed**](https://edstem.org/us/courses/78535/discussion/6647877) </small>\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44582fe4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda ðŸ“†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f6f02",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Today's focus is on **clustering**, an **unsupervised learning** method. We'll focus on $k$-means clustering, the most popular clustering technique, but discuss another clustering technique (agglomerative clustering) as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d863d6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- In our final lecture, we'll more examples of other techniques in machine learning that are small extensions to what we've covered so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da28e9e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤” (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030f3786",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clustering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1954398",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The taxonomy of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e0889d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/taxonomy.svg\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe18f5f9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In Lectures 11-19, we focused on building models for **regression**.<br><small>In regression, we predict a **continuous** target variable, $y$, using some features, $X$.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aef1178",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the past few lectures, we switched our focus to building models for **classification**.<br><small>In classification, we predict a **categorical** target variable, $y$, using some features, $X$.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54935949",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Both regression and classification are **supervised learning** methods.<br><small>In both regression and classification, our goal is to predict $y$ from $X$. The datasets we've used already had a $y$ variable.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877cc548",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What might an **unsupervised learning** problem look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0311dfed",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: TV show ratings ðŸ“º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f384174",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose we have the ratings that several customers of a streaming service gave to two popular TV shows: _Modern Family_ and _Stranger Things_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea1ab9",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c540781",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The data naturally falls into three groups, or **clusters**, based on users with similar preferences.<br><small>All we're given are the ratings each customer gave to the two shows; the customers aren't already part of any group.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005daab6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we ran the streaming service and could \"identify\" the three clusters, it could help inform us on who to make recommendations to.<br><small>For example, if someone in the bottom-right cluster likes _How I Met Your Mother_, we might recommend it to other members of the bottom-right cluster since they have similar tastes.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eed703b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **How do we algorithmically determine these clusters**, especially when there are too many dimensions to visualize?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd59c0c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2459e8c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Goal**: Given a set of $n$ data points stored as vectors in $\\mathbb{R}^d$, $\\vec x_1, \\vec x_2, ..., \\vec x_n$, and a positive integer $k$, **place the data points into $k$ clusters of nearby points**.<br><small>In the scatter plot below, $n = 9$ and $d = 2$.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dc1a95",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.show_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6368d2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Think of clusters as **colors**; in other words, the goal of clustering is to assign each point a color, such that points of the same color are similar to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92647161",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note, unlike with regression or classification, there is no \"right answer\" that we're trying to predict â€“ there is no $y$! This is what makes clustering **unsupervised**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1d72bc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bae1a1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Idea: Points in a cluster should be close to the center of the cluster.<br><small>The clustering method we're developing relies on this assumption.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea91d5dc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **One** technique for defining clusters involves choosing $k$ cluster centers, known as **centroids**.\n",
    "\n",
    "    $$\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k \\in \\mathbb{R}^d$$\n",
    "\n",
    "    For instance, $\\vec \\mu_2$ is the center of cluster 2.<br><small>Cluster 2 might be the set of points colored **<span style=\"color:blue\">blue</span>**, for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b5d49a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- These $k$ centroids define the $k$ clusters; **each data point \"belongs\" to the nearest centroid to it**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51662897",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our problem reduces to finding the **best locations** for the centroids.<br><small>Over the next few slides, we'll visualize several possible sets of centroids and the clusters they define.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7139aaa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With the following $k = 3$ centroids, the data are colored in the way that we'd expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ce7af",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 7), (8, 4), (8, 8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb43ad",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But here, even though $k = 3$, the data are not colored \"naturally\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69da87",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 7), (8, 4), (3, 7)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b88821",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nothing is stopping us from setting $k = 2$, for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ca86d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 7), (8, 4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3015e7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or $k = 5$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da73f4e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(4, 4), (5, 5), (6, 6), (7, 7), (8, 8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c3bfa7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflections on choosing a centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c7dbf1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Some values of $k$ seemed more intuitive than others; $k$ is a **hyperparameter** that we'll need to tune.<br><small>More on this later.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd07a358",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For a fixed $k$, some clusterings \"looked\" better than others; we'll need a way to quantify this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348da919",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As we did at the start of the second half of the course, we'll formulate an **objective function** to minimize. Specifically, we'll minimize **inertia**, $I$:\n",
    "\n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a366646",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Lower values of inertia lead to better clusterings; our goal is to find the set of centroids $\\vec \\mu_1, \\vec \\mu_2, ... \\vec \\mu_k$ that **minimize inertia**, $I$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffc0616",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "### Activity\n",
    "    \n",
    "Recall, inertia is defined as follows:\n",
    "    \n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$\n",
    "    \n",
    "<br>\n",
    "    \n",
    "Suppose we arrange the dataset below into $k = 2$ clusters. What is the **minimum possible inertia**?\n",
    "    \n",
    "<center><img src=\"imgs/example-q.png\" width=500></center>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77efca1c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## $k$-means clustering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc42995",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Minimizing inertia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b79399",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Goal**: Find the centroids $\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k$ that minimize inertia:\n",
    "\n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530dc1d7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Issue**: There is no efficient way to find the centroids that minimize inertia!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98efe41a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are $k^n$ possible assignments of points to clusters; it would be computationally infeasible to try them all.<br><small>It can be shown that finding the optimal centroid locations is NP-hard.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258f9df",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can't use calculus to minimize $I$, either â€“ we use calculus to minimize continuous functions, but the assignment of a point $\\vec x_i$ to a centroid $\\vec \\mu_j$ is a discrete operation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1478fa3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-means clustering (i.e. Lloyd's algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702dded",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Fortunately, there's an efficient algorithm that (tries to) find the centroid locations that minimize inertia. The resulting clustering technique is called **$k$-means clustering**.<br><small>Note that this has no relation to $k$-nearest neighbors, which we used for both regression and classification. Remember that clustering is an unsupervised technique!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61da9be",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "0. **Randomly** initialize $k$ centroids.<br><small>There are other ways of initializing the centroids as well.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878dd832",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Assign each point to the nearest centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a77ab04",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Move each centroid to the **center** of its group.<br><small>We compute the center of a group by taking the mean of the group's coordinates.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018014ab",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. **Repeat** steps 1 and 2 until the centroids stop changing!<br><small>This is an iterative algorithm!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb79ae",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's visualize a few iterations ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1eaf7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 5), (8, 10)], show_color=False, title='Step 0: Random Initialization<br>Red:(2, 5), Blue: (8, 10)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a694a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 5), (8, 10)], title='Iteration 1, Step 1: Assign each point to the nearest centroid<br>Red:(2, 5), Blue: (8, 10)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717ce58",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 5), (8, 10)], lines=True, title='Iteration 1, Step 1: Assign each point to the nearest centroid<br>Red:(2, 5), Blue: (8, 10); <b>Inertia = Sum(squared distances) = 156.25</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba08cd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(3.6, 6.8), (9.5, 7.125)], lines=True, assignments=[0] * 5 + [1] * 4, title='Iteration 1, Step 2: Move each centroid to the center of its group<br>Red:(3.6, 6.8), Blue: (9.5, 7.125); <b>Inertia = 85.1875</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c7a2a0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(3.6, 6.8), (9.5, 7.125)], assignments=[0] * 5 + [1] * 4, title='Iteration 1, Step 2: Move each centroid to the center of its group<br>Red:(3.6, 6.8), Blue: (9.5, 7.125); <b>Inertia = 85.1875</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b498e286",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(3.6, 6.8), (9.5, 7.125)], title='Iteration 2, Step 1: Assign each point to the nearest centroid<br>Red:(3.6, 6.8), Blue: (9.5, 7.125); <b>Inertia = 70.653125</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8d3d3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2.5, 7.75), (9.2, 6.3)], title='Iteration 2, Step 2: Move each centroid to the center of its group<br>Red:(2.5, 7.75), Blue: (9.2, 6.3); <b>Inertia = 58.35</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf59fd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2.5, 7.75), (9.2, 6.3)], title='Iteration 3, Step 1: Assign each point to the nearest centroid<br>No change, so algorithm terminates!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c4f129",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why does $k$-means work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932f7118",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- On each iteration, **inertia can only stay the same or decrease** â€“ it cannot increase.\n",
    "\n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c34be",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why? Step 1 and step 2 **alternate** minimizing inertia in different ways:\n",
    "    - In Step 1, we assign each point to the nearest centroid; this reduces the squared distance of each point to its closest centroid.\n",
    "    - In Step 2, we move the centroids to the **center (mean position)** of their groups; this reduces the total **squared** distance from a centroid to the points assigned to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec40a1a9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since there are only finitely many possible assignments of points to clusters, eventually the algorithm will terminate at some **potentially local** minimum.<br><small>Read more on the theory [**here**](https://www.cs.toronto.edu/~rgrosse/courses/csc311_f21/lectures/lec11.pdf).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb709bd2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's experiment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154d915",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's visualize more runs of the algorithm [**here**](https://www.naftaliharris.com/blog/visualizing-k-means-clustering).\n",
    "\n",
    "<center><img src=\"imgs/smiley.png\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed6fdf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To replicate the picture above, select \"I'll Choose\" and \"Smiley Face.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b73592",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In what sense is $k$-means _optimal_?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100b5b6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The algorithm discussed **isn't guaranteed** to find the centroids that minimize inertia; depending on the initially-chosen centroids, it may converge at a local minimum.<br><small>One solution is $k$-means++, which picks one centroid randomly and chooses the others in a way that maximizes distance from existing centroids. Read more [here](https://en.wikipedia.org/wiki/K-means%2B%2B).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8cde0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Even if $k$-means \"works\", the resulting clustering might not look \"right\" to humans. That is, the clustering that minimizes inertia doesn't necessarily look correct to us.<br><small>Remember, the core assumption in $k$-means is that **points in a cluster should be close to the center of the cluster**. This assumption isn't always true!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e28360",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing the number of clusters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eb2108",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Choosing $k$ in $k$-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7c1b5e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Given a dataset, how do we choose $k$, the number of clusters to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eb173a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The larger the value of $k$, the smaller inertia is.\n",
    "\n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edcf81e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $k = n$, then each point is a centroid, and inertia is 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cae5aa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But, the goal of clustering is to put the data into groups, so a large number of groups may not be meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e8ba9a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.show_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57096a48",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The elbow method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547ffea",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For several different values of $k$, let's compute the inertia of the resulting clustering, using the scatter plot from the previous slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424a4a8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.show_elbow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d89f0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **elbow method** says to choose the $k$ that appears at the elbow of the plot of inertia vs. $k$, since there are diminishing returns for using more than $k$ clusters.<br><small>Above, we see an elbow at $k = 3$, which gives us the $k$ that matches our natural intuition in this example.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b35e9c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In practice, the data may not have natural clusters, so the choice of $k$ may not be so obvious.<br><small>And, there may be other business reasons to choose a specific value of $k$, e.g. if you're told to categorize customers of a clothing item into 5 groups: XS, small, medium, large, XL.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff96427a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤” (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878be63b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: World Bank data ðŸŒŽ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dca3bf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22869f8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Below, we load in a dataset containing hundreds of attributes per country, taken from the [World Bank](https://databank.worldbank.org/source/world-development-indicators#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71369478",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "world_bank = pd.read_csv('data/world_bank_data.csv').set_index('country').fillna(0)\n",
    "world_bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ec389",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are $d = 209$ features, far too many to visualize before clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e9a7c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "world_bank.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a25249",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Dimensionality reduction** is another form of unsupervised learning that would help us visualize the data; we'll explore it briefly next class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed7b7c1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The elbow method, revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ccbdf5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How many clusters should we use? We'll need to resort to the elbow method, since we can't visualize the data to see how many \"natural\" clusters there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1987b5f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_elbow_world_bank(world_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b854df7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The choice is a bit more ambiguous than before; here, we'll use $k = 6$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b5b642",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clustering in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42c5a34",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To create our clusters, we'll use `KMeans` in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93543a1d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2673b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Like other models we've used in `sklearn`, we need to instantiate and fit a `KMeans` object. The difference is that the `fit` method only takes in a single `X`, not an `X` and `y`.<br><small>$k$-means is an unsupervised method, so there is no `y`.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4625ec4e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The default value of k is 8; we should generally specify another value.\n",
    "# We fix a random_state for reproducibility; remember the centroids are generally initialized randomly.    \n",
    "model = KMeans(n_clusters=6, random_state=15)\n",
    "model.fit(world_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c2cfe",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A fit `KMeans` instance has a `predict` method. It outputs the cluster whose centroid the data point is closest to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd90c3e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.predict(world_bank.loc[['United States']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b17b4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# It seems that the US and Canada are assigned to different clusters!\n",
    "model.predict(world_bank.loc[['Canada']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dd9ef6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspecting clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27483f75",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can view the countries assigned to each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135ca84",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "countries_and_clusters = pd.Series(model.labels_, index=world_bank.index)\n",
    "util.list_countries_by_cluster(countries_and_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d9f57",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It seems that the vast majority of countries are assigned to the same cluster!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcfb8b1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc8208",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.country_choropleth(countries_and_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d85db5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standardize before clustering!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d141a94b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Clustering, like $k$-nearest neighbors and regularization, is a **distance-based method**, meaning that it **depends on the scale of the data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15064da5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In `world_bank`, some features are in the millions or billions, while some are in the single digits. The larger features will influence cluster membership more than the smaller features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc207ab",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "world_bank.iloc[[1], -9:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec15fef",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solution**: Standardize before clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fa24d9",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd063e0f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_std = make_pipeline(StandardScaler(), KMeans(n_clusters=6, random_state=15)) # We fix a random state for reproducibility.\n",
    "model_std.fit(world_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71bef5c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Once we standarize, the sizes of the clusters seem to be a bit more evenly distributed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed73ff8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "countries_and_clusters_std = pd.Series(model_std[-1].labels_, index=world_bank.index)\n",
    "util.list_countries_by_cluster(countries_and_clusters_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2432f3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing clusters after standardizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e9124",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that the colors themselves are arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c005fe19",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.country_choropleth(countries_and_clusters_std, title='after Standardizing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ecf76",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agglomerative clustering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74a933b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overview of clustering methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd1ea14",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `sklearn` supports many different clustering methods! Read about them all [**here**](https://scikit-learn.org/1.5/modules/clustering.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2650afdb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/clustering-methods.png\" width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f3ebe",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Remember the \"no free lunch theorem\" â€“ there isn't a clustering method that is **always** better than all other clustering methods. It depends on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa21d0b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agglomerative clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a259f0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's revisit the ratings dataset from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9929c0a3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d522b7c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Agglomerative clustering**, a form of **hierarchical clustering**, creates clusters by:\n",
    "    1. Starting with each point as its own cluster.\n",
    "    2. Repeatedly **combining the two closest clusters** until there are only $k$ clusters remaining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91ffa34",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's visualize it in the context of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc524a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c178fa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The two closest clusters are <b><span style=\"color:brown\">cluster 7</span></b> and <b><span style=\"color:navy\">cluster 8</span></b>, so we merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7992626a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 1', labels=[0, 1, 2, 3, 4, 5, 6, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bff306",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now, the two closest clusters are <b><span style=\"color:cyan\">cluster 5</span></b> and <b><span style=\"color:magenta\">cluster 6</span></b>, so we merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6095fb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 2', labels=[0, 1, 2, 3, 4, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260b2bc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It's not clear what the next merge should be â€“ should <b><span style=\"color:orange\">cluster 4</span></b> merge with <b><span style=\"color:cyan\">cluster 5</span></b> or should <b><span style=\"color:green\">cluster 2</span></b> merge with <b><span style=\"color:purple\">cluster 3</span></b>?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb14290",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linkage criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1b0d8c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We need a way to measure the distance between two clusters.<br><small>For example, what is the \"distance\" between <b><span style=\"color:orange\">cluster 4</span></b> and <b><span style=\"color:cyan\">cluster 5</span></b> below?</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e8a08",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 2', labels=[0, 1, 2, 3, 4, 5, 5, 7, 7], width=500, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14401b5d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **linkage criteria** determines how to compute the distance between  two clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79637f83",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Some examples:\n",
    "    - Average linkage: The average distance between points in both clusters.\n",
    "    - Single linkage: The minimum distance between points in both clusters.\n",
    "    - Complete linkage: The maximum distance between points in both clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c310f7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 2', show_distances=[(1, 3), (0, 2), (0, 1), (2, 3), (4, 5)], labels=[0, 1, 2, 3, 4, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1178044",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We'll use single linkage, i.e.:\n",
    "\n",
    "$$\\text{distance(cluster $A$, cluster $B$)} = \\text{minimum distance between} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{any point in $A$ and any point in $B$}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd4341",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Here, there are lots of ties; we'll arbitrarily choose to merge <b><span style=\"color:orange\">cluster 4</span></b> and <b><span style=\"color:cyan\">cluster 5</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e060299b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 3', show_distances=[(0, 2), (2, 3)], labels=[0, 1, 2, 3, 5, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8384c950",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Again, there's a tie; we'll arbitrarily choose to merge <b><span style=\"color:green\">cluster 2</span></b> and <b><span style=\"color:purple\">cluster 3</span></b>.<br><small>We could have also merged <b><span style=\"color:green\">cluster 2</span></b> and <b><span style=\"color:red\">cluster 0</span></b>, since their minimum distance is also the same.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19586230",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 4', show_distances=[(0, 2), (1, 2)], labels=[0, 1, 2, 2, 5, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f5ab0a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Next, we merge <b><span style=\"color:green\">cluster 2</span></b> and <b><span style=\"color:red\">cluster 0</span></b>.<br><small>Why? Because the minimum distance between <b><span style=\"color:red\">cluster 0</span></b> and <b><span style=\"color:green\">cluster 2</span></b> is less than the minimum distance between <b><span style=\"color:blue\">cluster 1</span></b> and <b><span style=\"color:green\">cluster 2</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8458e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 5', labels=[2, 1, 2, 2, 5, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6cfe3a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- And finally, we merge <b><span style=\"color:green\">cluster 2</span></b> and <b><span style=\"color:blue\">cluster 1</span></b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d047cf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we just want $k = 3$ clusters, we stop here! If we wanted $k = 2$ clusters, we'd then merge the two closest clusters, based on the single linkage criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c4118f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-means vs. agglomerative clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536ef7db",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- On what sorts of datasets does agglomerative clustering perform better than $k$-means clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f7c279",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_scatter_comp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6877c41",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.show_scatter_comp_k_means(k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2145c63",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that $k$-means clustering optimizes for inertia, not \"blobiness.\"<br>It doesn't work well when the natural clusters are of uneven sizes.<br><small>Read more [**here**](https://stats.stackexchange.com/questions/133656/how-to-understand-the-drawbacks-of-k-means).</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239d4f6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.show_scatter_comp_agg(k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5155dc15",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Another metric that's used to compare different clusterings is the **silhouette score**.<br><small>Read more [**here**](https://en.wikipedia.org/wiki/Silhouette_(clustering)).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa6d192",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤” (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
